{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blurred421/LFD473-code/blob/main/labs/jb_Lab%205A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67609b90",
      "metadata": {
        "id": "67609b90"
      },
      "source": [
        "# Lab Instructions\n",
        "\n",
        "In the lab, you're presented a task such as building a dataset, training a model, or writing a training loop, and we'll provide the code structured in such a way that you can fill in the blanks in the code using the knowledge you acquired in the chapters that precede the lab. You should be able to find appropriate snippets of code in the course content that work well in the lab with minor or no adjustments.\n",
        "\n",
        "The blanks in the code are indicated by ellipsis (`...`) and comments (`# write your code here`).\n",
        "\n",
        "In some cases, we'll provide you partial code to ensure the right variables are populated and any code that follows it runs accordingly.\n",
        "\n",
        "```python\n",
        "# write your code here\n",
        "x = ...\n",
        "```\n",
        "\n",
        "The solution should be a single statement that replaces the ellipsis, such as:\n",
        "\n",
        "```python\n",
        "# write your code here\n",
        "x = [0, 1, 2]\n",
        "```\n",
        "\n",
        "In some other cases, when there is no new variable being created, the blanks are shown like in the example below:\n",
        "\n",
        "```python\n",
        "# write your code here\n",
        "...\n",
        "```\n",
        "\n",
        "Although we're showing you only a single ellipsis (`...`), you may have to write more than one line of code to complete the step, such as:\n",
        "\n",
        "```python\n",
        "# write your code here\n",
        "for i, xi in enumerate(x):\n",
        "    x[i] = xi * 2\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "888c5e9f",
      "metadata": {
        "id": "888c5e9f"
      },
      "source": [
        "## 12.8 Lab 5A: Fine-Tuning Object Detection Models\n",
        "\n",
        "In this lab, you'll build a dataset, including data augmentation, and fine-tune a custom object detection model by replacing its standard backbone with a different computer vision model. In the end, you'll evaluate the model using metrics from the COCO challenge."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ce02517",
      "metadata": {
        "id": "3ce02517"
      },
      "source": [
        "### 12.8.1 Oxford-IIIT Pet Dataset\n",
        "\n",
        "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch0/data_step1.png)\n",
        "\n",
        "You'll build a dataset using the images and annotations from the [Oxford-IIIT Pet dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/):\n",
        "\n",
        "\"_We have created a 37 category pet dataset with roughly 200 images for each class. The images have a large variations in scale, pose and lighting. All images have an associated ground truth annotation of breed, head ROI, and pixel level trimap segmentation._\"\n",
        "\n",
        "You will load the data using [PyTorch's built-in class](https://pytorch.org/vision/stable/generated/torchvision.datasets.OxfordIIITPet.html), but you're tasked with preprocessing the annotations and building a dataset that is compatible with V2 transforms for data augmentation (without wrapping the built-in dataset, that is).\n",
        "\n",
        "First, load the data to the a folder of your choice (e.g. `./pets`), making sure to retrieve the `trainval` split (which has annotations), and choose both target types, `category` and `segmentation`, since you'll be fine-tuning a model to detect pets on images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "432568a3",
      "metadata": {
        "id": "432568a3",
        "outputId": "a4f096a3-3d33-4dbc-f307-ac00ff8a1af0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/pets/images.tar.gz to pets/oxford-iiit-pet/images.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 792M/792M [00:42<00:00, 18.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting pets/oxford-iiit-pet/images.tar.gz to pets/oxford-iiit-pet\n",
            "Downloading https://thor.robots.ox.ac.uk/pets/annotations.tar.gz to pets/oxford-iiit-pet/annotations.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19.2M/19.2M [00:01<00:00, 11.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting pets/oxford-iiit-pet/annotations.tar.gz to pets/oxford-iiit-pet\n"
          ]
        }
      ],
      "source": [
        "from torchvision.datasets import OxfordIIITPet\n",
        "\n",
        "root_folder = './pets'\n",
        "# write the arguments to create an instance of the dataset\n",
        "pets = OxfordIIITPet(root=root_folder, split='trainval', target_types=['category', 'segmentation'], download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a68cf78",
      "metadata": {
        "id": "2a68cf78"
      },
      "source": [
        "### 12.8.2 Annotations\n",
        "\n",
        "The annotations follow the Pascal VOC challenge format, and are stored as individual XML files, one for each annotated image, inside the `oxford-iiit-pet/annotations/xmls` subfolder. Use the `xml_to_csv()` helper function to convert all these files into a Pandas dataframe and inspect its contents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "af0411c1",
      "metadata": {
        "id": "af0411c1"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "def xml_to_csv(path):\n",
        "    \"\"\"Iterates through all .xml files (generated by labelImg) in a given directory and combines\n",
        "    them in a single Pandas dataframe.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    path : str\n",
        "        The path containing the .xml files\n",
        "    Returns\n",
        "    -------\n",
        "    Pandas DataFrame\n",
        "        The produced dataframe\n",
        "    \"\"\"\n",
        "\n",
        "    xml_list = []\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        filename = root.find('filename').text\n",
        "        width = int(root.find('size').find('width').text)\n",
        "        height = int(root.find('size').find('height').text)\n",
        "        for member in root.findall('object'):\n",
        "            bndbox = member.find('bndbox')\n",
        "            value = (filename,\n",
        "                     width,\n",
        "                     height,\n",
        "                     member.find('name').text,\n",
        "                     int(bndbox.find('xmin').text),\n",
        "                     int(bndbox.find('ymin').text),\n",
        "                     int(bndbox.find('xmax').text),\n",
        "                     int(bndbox.find('ymax').text),\n",
        "                     )\n",
        "            xml_list.append(value)\n",
        "    column_name = ['filename', 'width', 'height',\n",
        "                   'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "    return xml_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fdfbc4e2",
      "metadata": {
        "id": "fdfbc4e2",
        "outputId": "bf332461-78f2-401b-dc2a-69b78befb9d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       filename  width  height class  xmin  ymin  xmax  ymax\n",
              "0      american_bulldog_200.jpg    500     319   dog   177     9   353   143\n",
              "1     yorkshire_terrier_118.jpg    240     300   dog    36     2   178   162\n",
              "2     yorkshire_terrier_162.jpg    500     375   dog   220    38   347   235\n",
              "3            pomeranian_113.jpg    300     225   dog   137    61   192   148\n",
              "4               Persian_134.jpg    500     375   cat   336    15   486   158\n",
              "...                         ...    ...     ...   ...   ...   ...   ...   ...\n",
              "3682            Ragdoll_153.jpg    500     415   cat   284    11   464   198\n",
              "3683             Bombay_145.jpg    500     337   cat   297    24   478   185\n",
              "3684            samoyed_102.jpg    500     408   dog    90    84   166   183\n",
              "3685      japanese_chin_127.jpg    375     500   dog   126   104   248   197\n",
              "3686   scottish_terrier_111.jpg    500     376   dog    92   102   158   213\n",
              "\n",
              "[3687 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf540f58-1a0c-400d-9bbc-0e78329a5df7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>class</th>\n",
              "      <th>xmin</th>\n",
              "      <th>ymin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymax</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>american_bulldog_200.jpg</td>\n",
              "      <td>500</td>\n",
              "      <td>319</td>\n",
              "      <td>dog</td>\n",
              "      <td>177</td>\n",
              "      <td>9</td>\n",
              "      <td>353</td>\n",
              "      <td>143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>yorkshire_terrier_118.jpg</td>\n",
              "      <td>240</td>\n",
              "      <td>300</td>\n",
              "      <td>dog</td>\n",
              "      <td>36</td>\n",
              "      <td>2</td>\n",
              "      <td>178</td>\n",
              "      <td>162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>yorkshire_terrier_162.jpg</td>\n",
              "      <td>500</td>\n",
              "      <td>375</td>\n",
              "      <td>dog</td>\n",
              "      <td>220</td>\n",
              "      <td>38</td>\n",
              "      <td>347</td>\n",
              "      <td>235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pomeranian_113.jpg</td>\n",
              "      <td>300</td>\n",
              "      <td>225</td>\n",
              "      <td>dog</td>\n",
              "      <td>137</td>\n",
              "      <td>61</td>\n",
              "      <td>192</td>\n",
              "      <td>148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Persian_134.jpg</td>\n",
              "      <td>500</td>\n",
              "      <td>375</td>\n",
              "      <td>cat</td>\n",
              "      <td>336</td>\n",
              "      <td>15</td>\n",
              "      <td>486</td>\n",
              "      <td>158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3682</th>\n",
              "      <td>Ragdoll_153.jpg</td>\n",
              "      <td>500</td>\n",
              "      <td>415</td>\n",
              "      <td>cat</td>\n",
              "      <td>284</td>\n",
              "      <td>11</td>\n",
              "      <td>464</td>\n",
              "      <td>198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3683</th>\n",
              "      <td>Bombay_145.jpg</td>\n",
              "      <td>500</td>\n",
              "      <td>337</td>\n",
              "      <td>cat</td>\n",
              "      <td>297</td>\n",
              "      <td>24</td>\n",
              "      <td>478</td>\n",
              "      <td>185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3684</th>\n",
              "      <td>samoyed_102.jpg</td>\n",
              "      <td>500</td>\n",
              "      <td>408</td>\n",
              "      <td>dog</td>\n",
              "      <td>90</td>\n",
              "      <td>84</td>\n",
              "      <td>166</td>\n",
              "      <td>183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3685</th>\n",
              "      <td>japanese_chin_127.jpg</td>\n",
              "      <td>375</td>\n",
              "      <td>500</td>\n",
              "      <td>dog</td>\n",
              "      <td>126</td>\n",
              "      <td>104</td>\n",
              "      <td>248</td>\n",
              "      <td>197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3686</th>\n",
              "      <td>scottish_terrier_111.jpg</td>\n",
              "      <td>500</td>\n",
              "      <td>376</td>\n",
              "      <td>dog</td>\n",
              "      <td>92</td>\n",
              "      <td>102</td>\n",
              "      <td>158</td>\n",
              "      <td>213</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3687 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf540f58-1a0c-400d-9bbc-0e78329a5df7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bf540f58-1a0c-400d-9bbc-0e78329a5df7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bf540f58-1a0c-400d-9bbc-0e78329a5df7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cd477f0c-9543-4c5c-ab3b-bd25dd9c3035\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cd477f0c-9543-4c5c-ab3b-bd25dd9c3035')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cd477f0c-9543-4c5c-ab3b-bd25dd9c3035 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c401c021-2549-4dc7-9c3d-2eb45587dbb9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('xml_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c401c021-2549-4dc7-9c3d-2eb45587dbb9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('xml_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "xml_df",
              "summary": "{\n  \"name\": \"xml_df\",\n  \"rows\": 3687,\n  \"fields\": [\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3686,\n        \"samples\": [\n          \"leonberger_128.jpg\",\n          \"Bombay_157.jpg\",\n          \"english_setter_116.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 126,\n        \"min\": 114,\n        \"max\": 3264,\n        \"num_unique_values\": 292,\n        \"samples\": [\n          342,\n          235,\n          350\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 116,\n        \"min\": 108,\n        \"max\": 2606,\n        \"num_unique_values\": 319,\n        \"samples\": [\n          264,\n          482,\n          393\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"cat\",\n          \"dog\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xmin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 85,\n        \"min\": 1,\n        \"max\": 1715,\n        \"num_unique_values\": 364,\n        \"samples\": [\n          312,\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ymin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49,\n        \"min\": 1,\n        \"max\": 367,\n        \"num_unique_values\": 242,\n        \"samples\": [\n          24,\n          79\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xmax\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 109,\n        \"min\": 67,\n        \"max\": 2555,\n        \"num_unique_values\": 429,\n        \"samples\": [\n          120,\n          446\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ymax\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 84,\n        \"min\": 44,\n        \"max\": 1777,\n        \"num_unique_values\": 393,\n        \"samples\": [\n          150,\n          338\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# write your code here\n",
        "xml_df = xml_to_csv(f'{root_folder}/oxford-iiit-pet/annotations/xmls')\n",
        "xml_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb0ee5e7",
      "metadata": {
        "id": "eb0ee5e7"
      },
      "source": [
        "The annotations contain the box coordinates in the Pascal VOC system (`[xmin, ymin, xmax, ymax]`), but they only have two main classes, cats and dogs, instead of the expected 37 classes found in the description. As it turns out, there are more files in the `annotations` folder, namely, `list.txt`, `trainval.txt`, and `test.txt`.\n",
        "\n",
        "If you're in Google Colab, the command below will list the files inside the `annotations` folder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "162fd285",
      "metadata": {
        "id": "162fd285",
        "outputId": "4417742a-a1da-48ab-e0dd-f08191ff7ce7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1096\n",
            "-rw-r--r-- 1 501 staff 172300 Jun 29  2012 list.txt\n",
            "-rw-r--r-- 1 501 staff   1476 Jun 30  2012 README\n",
            "-rw-r--r-- 1 501 staff  84319 Jun 29  2012 test.txt\n",
            "-rw-r--r-- 1 501 staff  87776 Jun 29  2012 trainval.txt\n",
            "drwxr-xr-x 2 501 staff 618496 Jun 18  2012 trimaps\n",
            "drwxr-xr-x 2 501 staff 147456 Jun 29  2012 xmls\n"
          ]
        }
      ],
      "source": [
        "# if you chose a different root folder, change it accordingly\n",
        "!ls -l ./pets/oxford-iiit-pet/annotations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aea04722",
      "metadata": {
        "id": "aea04722"
      },
      "source": [
        "Let's take a look at the `list.txt` file.\n",
        "\n",
        "If you're in Google Colab, the command below will show you the first few lines of the `list.txt` file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "befa668e",
      "metadata": {
        "id": "befa668e",
        "outputId": "d1cc5feb-7d10-43b7-efe7-1245f6a81fe7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Image CLASS-ID SPECIES BREED ID\n",
            "#ID: 1:37 Class ids\n",
            "#SPECIES: 1:Cat 2:Dog\n",
            "#BREED ID: 1-25:Cat 1:12:Dog\n",
            "#All images with 1st letter as captial are cat images\n",
            "#images with small first letter are dog images\n",
            "Abyssinian_100 1 1 1\n",
            "Abyssinian_101 1 1 1\n",
            "Abyssinian_102 1 1 1\n",
            "Abyssinian_103 1 1 1\n"
          ]
        }
      ],
      "source": [
        "!head ./pets/oxford-iiit-pet/annotations/list.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48445f85",
      "metadata": {
        "id": "48445f85"
      },
      "source": [
        "It contains a list of all images in the dataset, organized in four columns separated by spaces: Image, CLASS-ID, SPECIES, BREED ID. As it turns out, the \"class\" from the XML file is actually the species. We're interested in the true class ids, from 1 to 37, as stated in the description.\n",
        "\n",
        "Now, let's take a look at the file corresponding to the data you loaded, the `trainval` split.\n",
        "\n",
        "If you're in Google Colab, the command below will show you the first few lines of the `trainval.txt` file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "12022f87",
      "metadata": {
        "id": "12022f87",
        "outputId": "79f4c7d9-0f3e-4574-d467-47355cbf56bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Abyssinian_100 1 1 1\n",
            "Abyssinian_101 1 1 1\n",
            "Abyssinian_102 1 1 1\n",
            "Abyssinian_103 1 1 1\n",
            "Abyssinian_104 1 1 1\n",
            "Abyssinian_105 1 1 1\n",
            "Abyssinian_106 1 1 1\n",
            "Abyssinian_107 1 1 1\n",
            "Abyssinian_108 1 1 1\n",
            "Abyssinian_109 1 1 1\n"
          ]
        }
      ],
      "source": [
        "!head ./pets/oxford-iiit-pet/annotations/trainval.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fc69f55",
      "metadata": {
        "id": "8fc69f55"
      },
      "source": [
        "It clearly follows the same structure as the previous file, but it does not contain any headers, and it lists only the images that belong to the original train and validation split.\n",
        "\n",
        "We can load it in Pandas for easier visualization (just run the code below as is to visualize the dataframe with the information from the `trainval.txt` file):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c7a85a4a",
      "metadata": {
        "id": "c7a85a4a",
        "outputId": "2e571ac1-a8e2-4980-93dc-a48fdabb2a03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   filename  class_id  species  breed_id\n",
              "0            Abyssinian_100         1        1         1\n",
              "1            Abyssinian_101         1        1         1\n",
              "2            Abyssinian_102         1        1         1\n",
              "3            Abyssinian_103         1        1         1\n",
              "4            Abyssinian_104         1        1         1\n",
              "...                     ...       ...      ...       ...\n",
              "3675  yorkshire_terrier_187        37        2        25\n",
              "3676  yorkshire_terrier_188        37        2        25\n",
              "3677  yorkshire_terrier_189        37        2        25\n",
              "3678   yorkshire_terrier_18        37        2        25\n",
              "3679  yorkshire_terrier_190        37        2        25\n",
              "\n",
              "[3680 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb783a18-8f66-44c9-9c8e-bcc7ce1e50e3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>class_id</th>\n",
              "      <th>species</th>\n",
              "      <th>breed_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Abyssinian_100</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Abyssinian_101</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Abyssinian_102</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Abyssinian_103</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Abyssinian_104</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3675</th>\n",
              "      <td>yorkshire_terrier_187</td>\n",
              "      <td>37</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3676</th>\n",
              "      <td>yorkshire_terrier_188</td>\n",
              "      <td>37</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3677</th>\n",
              "      <td>yorkshire_terrier_189</td>\n",
              "      <td>37</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3678</th>\n",
              "      <td>yorkshire_terrier_18</td>\n",
              "      <td>37</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3679</th>\n",
              "      <td>yorkshire_terrier_190</td>\n",
              "      <td>37</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3680 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb783a18-8f66-44c9-9c8e-bcc7ce1e50e3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eb783a18-8f66-44c9-9c8e-bcc7ce1e50e3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eb783a18-8f66-44c9-9c8e-bcc7ce1e50e3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a9f771da-065d-44ab-b4c1-15d2b69c58cf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a9f771da-065d-44ab-b4c1-15d2b69c58cf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a9f771da-065d-44ab-b4c1-15d2b69c58cf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_67981b00-c687-43d0-bf44-f80267e7e75e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('trainval_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_67981b00-c687-43d0-bf44-f80267e7e75e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('trainval_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "trainval_df",
              "summary": "{\n  \"name\": \"trainval_df\",\n  \"rows\": 3680,\n  \"fields\": [\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3680,\n        \"samples\": [\n          \"newfoundland_101\",\n          \"keeshond_190\",\n          \"english_cocker_spaniel_147\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 1,\n        \"max\": 37,\n        \"num_unique_values\": 37,\n        \"samples\": [\n          18,\n          14,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"species\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"breed_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 1,\n        \"max\": 25,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          9,\n          17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "trainval_df = pd.read_csv('./pets/oxford-iiit-pet/annotations/trainval.txt', sep=' ', header=None, names=['filename', 'class_id', 'species', 'breed_id'])\n",
        "trainval_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0b24f47",
      "metadata": {
        "id": "b0b24f47"
      },
      "source": [
        "Each filename has its own corresponding class index (`class_id`), but the label itself, as the descriptive name corresponding to the category is only available as part of the filename itself. We can easily extract it, though. Just run the code below as is to create a new column (`category`) in the dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fade5fcd",
      "metadata": {
        "id": "fade5fcd"
      },
      "outputs": [],
      "source": [
        "trainval_df['category'] = trainval_df['filename'].apply(lambda v: ' '.join([w.capitalize()\n",
        "                                                                            for w in v.split('_')[:-1]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb328f7a",
      "metadata": {
        "id": "cb328f7a"
      },
      "source": [
        "Moreover, there are 3,680 rows, one for each image, but there are 3,687 annotations retrieved from the XML files. Why? It is important to highlight that:\n",
        "- some images may have more than one annotation/box - you saw that already in the Penn-Fudan dataset\n",
        "- some images probably have no annotations/boxes (you'll see that soon)\n",
        "\n",
        "We'll use the same custom dataset class `ObjDetectionDataset` once again, since it is prepared to take a CSV file or Pandas dataframe containing the annotations (filename, labels, xmin, ymin, xmax, and ymax columns), but keep in mind that only the filenames in the file/dataframe are going to be considered by it.\n",
        "\n",
        "Therefore, we need to build an annotations file/dataframe that includes filenames that have no annotations as well. It is better to keep images without annotations as negative cases, so we merge both dataframes and make sure that:\n",
        "- every filename is kept, so there are still 3,680 unique filenames after merging\n",
        "- the resulting dataframe has, at least, the following columns: `filename`, `label`, `category`, `xmin`, `ymin`, `xmax`, and `ymax`\n",
        "\n",
        "Run the code below as is to build the corresponding dataframe of annotations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "064de5ad",
      "metadata": {
        "id": "064de5ad",
        "outputId": "97237f41-0dac-4f59-f7ee-fd681a34b4f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       filename  label           category  width  height  \\\n",
              "0            Abyssinian_100.jpg      1         Abyssinian  394.0   500.0   \n",
              "1            Abyssinian_101.jpg      1         Abyssinian  450.0   313.0   \n",
              "2            Abyssinian_102.jpg      1         Abyssinian  500.0   465.0   \n",
              "3            Abyssinian_103.jpg      1         Abyssinian  500.0   351.0   \n",
              "4            Abyssinian_104.jpg      1         Abyssinian    NaN     NaN   \n",
              "...                         ...    ...                ...    ...     ...   \n",
              "3676  yorkshire_terrier_187.jpg     37  Yorkshire Terrier  500.0   334.0   \n",
              "3677  yorkshire_terrier_188.jpg     37  Yorkshire Terrier  500.0   334.0   \n",
              "3678  yorkshire_terrier_189.jpg     37  Yorkshire Terrier  500.0   334.0   \n",
              "3679   yorkshire_terrier_18.jpg     37  Yorkshire Terrier  500.0   375.0   \n",
              "3680  yorkshire_terrier_190.jpg     37  Yorkshire Terrier  406.0   500.0   \n",
              "\n",
              "       xmin  ymin   xmax   ymax  \n",
              "0     151.0  71.0  335.0  267.0  \n",
              "1      54.0  36.0  319.0  235.0  \n",
              "2      23.0  27.0  325.0  320.0  \n",
              "3     241.0  68.0  362.0  196.0  \n",
              "4       NaN   NaN    NaN    NaN  \n",
              "...     ...   ...    ...    ...  \n",
              "3676  187.0  49.0  317.0  181.0  \n",
              "3677   94.0  36.0  378.0  263.0  \n",
              "3678  274.0  84.0  402.0  207.0  \n",
              "3679   52.0  23.0  289.0  183.0  \n",
              "3680   78.0  62.0  305.0  256.0  \n",
              "\n",
              "[3681 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e931327e-42f7-4ee6-8337-a3363b582784\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>label</th>\n",
              "      <th>category</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>xmin</th>\n",
              "      <th>ymin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymax</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Abyssinian_100.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>Abyssinian</td>\n",
              "      <td>394.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>151.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>335.0</td>\n",
              "      <td>267.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Abyssinian_101.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>Abyssinian</td>\n",
              "      <td>450.0</td>\n",
              "      <td>313.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>319.0</td>\n",
              "      <td>235.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Abyssinian_102.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>Abyssinian</td>\n",
              "      <td>500.0</td>\n",
              "      <td>465.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>325.0</td>\n",
              "      <td>320.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Abyssinian_103.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>Abyssinian</td>\n",
              "      <td>500.0</td>\n",
              "      <td>351.0</td>\n",
              "      <td>241.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>362.0</td>\n",
              "      <td>196.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Abyssinian_104.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>Abyssinian</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3676</th>\n",
              "      <td>yorkshire_terrier_187.jpg</td>\n",
              "      <td>37</td>\n",
              "      <td>Yorkshire Terrier</td>\n",
              "      <td>500.0</td>\n",
              "      <td>334.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>317.0</td>\n",
              "      <td>181.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3677</th>\n",
              "      <td>yorkshire_terrier_188.jpg</td>\n",
              "      <td>37</td>\n",
              "      <td>Yorkshire Terrier</td>\n",
              "      <td>500.0</td>\n",
              "      <td>334.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>378.0</td>\n",
              "      <td>263.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3678</th>\n",
              "      <td>yorkshire_terrier_189.jpg</td>\n",
              "      <td>37</td>\n",
              "      <td>Yorkshire Terrier</td>\n",
              "      <td>500.0</td>\n",
              "      <td>334.0</td>\n",
              "      <td>274.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>402.0</td>\n",
              "      <td>207.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3679</th>\n",
              "      <td>yorkshire_terrier_18.jpg</td>\n",
              "      <td>37</td>\n",
              "      <td>Yorkshire Terrier</td>\n",
              "      <td>500.0</td>\n",
              "      <td>375.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>289.0</td>\n",
              "      <td>183.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3680</th>\n",
              "      <td>yorkshire_terrier_190.jpg</td>\n",
              "      <td>37</td>\n",
              "      <td>Yorkshire Terrier</td>\n",
              "      <td>406.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>305.0</td>\n",
              "      <td>256.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3681 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e931327e-42f7-4ee6-8337-a3363b582784')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e931327e-42f7-4ee6-8337-a3363b582784 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e931327e-42f7-4ee6-8337-a3363b582784');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ddab931d-5735-49b2-ad6b-3ab78fd73d87\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ddab931d-5735-49b2-ad6b-3ab78fd73d87')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ddab931d-5735-49b2-ad6b-3ab78fd73d87 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a1a01e8a-6f06-4ada-bae6-b1f264f6b63a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('annotations_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a1a01e8a-6f06-4ada-bae6-b1f264f6b63a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('annotations_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "annotations_df",
              "summary": "{\n  \"name\": \"annotations_df\",\n  \"rows\": 3681,\n  \"fields\": [\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3680,\n        \"samples\": [\n          \"newfoundland_101.jpg\",\n          \"keeshond_190.jpg\",\n          \"english_cocker_spaniel_147.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 1,\n        \"max\": 37,\n        \"num_unique_values\": 37,\n        \"samples\": [\n          18,\n          14,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 37,\n        \"samples\": [\n          \"Japanese Chin\",\n          \"English Setter\",\n          \"Beagle\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 126.30933002374951,\n        \"min\": 114.0,\n        \"max\": 3264.0,\n        \"num_unique_values\": 292,\n        \"samples\": [\n          457.0,\n          368.0,\n          290.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 116.68437555070518,\n        \"min\": 108.0,\n        \"max\": 2606.0,\n        \"num_unique_values\": 319,\n        \"samples\": [\n          330.0,\n          321.0,\n          1200.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xmin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 85.42483983822424,\n        \"min\": 1.0,\n        \"max\": 1715.0,\n        \"num_unique_values\": 364,\n        \"samples\": [\n          185.0,\n          20.0,\n          238.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ymin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49.68556972826304,\n        \"min\": 1.0,\n        \"max\": 367.0,\n        \"num_unique_values\": 242,\n        \"samples\": [\n          81.0,\n          76.0,\n          154.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xmax\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 109.56174008123614,\n        \"min\": 67.0,\n        \"max\": 2555.0,\n        \"num_unique_values\": 429,\n        \"samples\": [\n          129.0,\n          315.0,\n          111.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ymax\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 84.60482859629506,\n        \"min\": 44.0,\n        \"max\": 1777.0,\n        \"num_unique_values\": 393,\n        \"samples\": [\n          317.0,\n          505.0,\n          313.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "trainval_df['filename'] = trainval_df['filename'].apply(lambda v: f'{v}.jpg')\n",
        "annotations_df = trainval_df.merge(xml_df, how='left', on='filename')\n",
        "\n",
        "colnames = ['filename', 'label', 'category', 'width', 'height', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "annotations_df = annotations_df.rename(columns={'class_id': 'label'})[colnames]\n",
        "annotations_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c28adb2",
      "metadata": {
        "id": "1c28adb2",
        "outputId": "677aaa7e-af8b-4bfb-ebda-4a24b18ac751"
      },
      "source": [
        "Besides, we'll use the resulting dataframe to build a `id2label` dictionary to map class id into the corresponding category. Run the code below as is to build the dictionary:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "db1710e5",
      "metadata": {
        "id": "db1710e5",
        "outputId": "2c9dcada-6301-42cd-81d8-ed25d4548593",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'Abyssinian',\n",
              " 2: 'American Bulldog',\n",
              " 3: 'American Pit Bull Terrier',\n",
              " 4: 'Basset Hound',\n",
              " 5: 'Beagle',\n",
              " 6: 'Bengal',\n",
              " 7: 'Birman',\n",
              " 8: 'Bombay',\n",
              " 9: 'Boxer',\n",
              " 10: 'British Shorthair',\n",
              " 11: 'Chihuahua',\n",
              " 12: 'Egyptian Mau',\n",
              " 13: 'English Cocker Spaniel',\n",
              " 14: 'English Setter',\n",
              " 15: 'German Shorthaired',\n",
              " 16: 'Great Pyrenees',\n",
              " 17: 'Havanese',\n",
              " 18: 'Japanese Chin',\n",
              " 19: 'Keeshond',\n",
              " 20: 'Leonberger',\n",
              " 21: 'Maine Coon',\n",
              " 22: 'Miniature Pinscher',\n",
              " 23: 'Newfoundland',\n",
              " 24: 'Persian',\n",
              " 25: 'Pomeranian',\n",
              " 26: 'Pug',\n",
              " 27: 'Ragdoll',\n",
              " 28: 'Russian Blue',\n",
              " 29: 'Saint Bernard',\n",
              " 30: 'Samoyed',\n",
              " 31: 'Scottish Terrier',\n",
              " 32: 'Shiba Inu',\n",
              " 33: 'Siamese',\n",
              " 34: 'Sphynx',\n",
              " 35: 'Staffordshire Bull Terrier',\n",
              " 36: 'Wheaten Terrier',\n",
              " 37: 'Yorkshire Terrier'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "id2label = dict(annotations_df[['label', 'category']].drop_duplicates().values)\n",
        "id2label"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7527fd4c",
      "metadata": {
        "id": "7527fd4c"
      },
      "source": [
        "Let's run some assert commands to ensure everything is as expected. Run the code below as is. It shouldn't raise any errors nor produce any output. If an error is raised, you should double-check the code for loading the dataset and its annotations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "fa7d39d2",
      "metadata": {
        "id": "fa7d39d2"
      },
      "outputs": [],
      "source": [
        "assert len(annotations_df['filename'].unique()) == 3680\n",
        "assert len(id2label.values()) == 37\n",
        "assert len(annotations_df) == 3681"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f2e25b4",
      "metadata": {
        "id": "2f2e25b4"
      },
      "source": [
        "Shouldn'it be 3,687? Perhaps even more, since it should also include images without any annotations? It actually should, but some of the annotated images were excluded from the `trainval.txt` list of files for some unknown reason. In case you're curious, these are the images. Run the code below as is to visualize the extra annotations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e528296e",
      "metadata": {
        "id": "e528296e",
        "outputId": "de746316-bc66-4bbe-b386-80d027f0ad2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Bombay_11.jpg',\n",
              " 'Bombay_189.jpg',\n",
              " 'Bombay_190.jpg',\n",
              " 'Bombay_192.jpg',\n",
              " 'Egyptian_Mau_129.jpg',\n",
              " 'Egyptian_Mau_183.jpg',\n",
              " 'Siamese_203.jpg',\n",
              " 'english_cocker_spaniel_162.jpg',\n",
              " 'english_cocker_spaniel_163.jpg',\n",
              " 'english_cocker_spaniel_164.jpg',\n",
              " 'english_cocker_spaniel_179.jpg',\n",
              " 'newfoundland_152.jpg',\n",
              " 'newfoundland_153.jpg',\n",
              " 'newfoundland_154.jpg',\n",
              " 'newfoundland_155.jpg'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "extra_annotations = set(xml_df['filename'].unique()).difference(set(annotations_df['filename'].unique()))\n",
        "extra_annotations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60d19d78",
      "metadata": {
        "id": "60d19d78"
      },
      "source": [
        "The whole point of this apparent detour from our main job here - fine-tuning an object detection model - is to illustrate the fact that every dataset has its issues, and you should always take your time to investigate how it's organized, if there are quality issues, and ensure it's in the right shape to be loaded into an instance of your dataset class.\n",
        "\n",
        "By the way, PyTorch's built-in dataset class for the Oxford-IIIT Pet Dataset handles this preprocssing (splitting filenames, building id2label dictionary, etc) in its [constructor method](https://pytorch.org/vision/main/_modules/torchvision/datasets/oxford_iiit_pet.html), in case you'd like to check it out."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e6986c8",
      "metadata": {
        "id": "9e6986c8"
      },
      "source": [
        "### 12.8.3 Train-Validation Split\n",
        "\n",
        "The original list of files does not give any indication regarding the split between training and validation sets, so you'll have to do it yourself.\n",
        "\n",
        "Our suggestion is to shuffle the filenames, and take a large part of them (e.g. 3,000) as training set, and the remaining files as validation set.\n",
        "\n",
        "Split the annotations dataframe in two, as the filenames in each dataframe determine which files are going be part of each dataset (assuming you're using our `ObjDetectionDataset`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3a20f284",
      "metadata": {
        "id": "3a20f284"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(11)\n",
        "\n",
        "# Get all (unique) file names from the annotations dataframe\n",
        "# write your code here\n",
        "fnames = sorted(annotations_df['filename'].unique())\n",
        "np.random.shuffle(fnames)\n",
        "\n",
        "# Create a boolean pandas series to determine if a given annotation belongs\n",
        "# to the training set\n",
        "# Tip: don't forget that images may have multiple annotations - make sure\n",
        "# two annotations of the same image don't end up in different sets\n",
        "# write your code here\n",
        "is_train = annotations_df['filename'].isin(fnames[:3000])\n",
        "\n",
        "annotations = {}\n",
        "# Use the boolean series to slice the annotations dataframe\n",
        "# write your code here\n",
        "annotations['train'] = annotations_df[is_train]\n",
        "annotations['val'] = annotations_df[~is_train]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5082d0b1",
      "metadata": {
        "id": "5082d0b1"
      },
      "source": [
        "### 12.8.4 Loading Model's Weights\n",
        "\n",
        "You're using a new backbone for your Faster R-CNN model, so you need to pick one that's different from ResNet50. You could, for example, choose a smaller model from the ResNet family, but it's likely more fun to choose a completely different model instead. We suggest you use MobileNet V2 as the new backbone.\n",
        "\n",
        "Once you choose the model, load its pretrained weights and the prescribed transformations that come with it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "2Botj0epelN4",
      "metadata": {
        "id": "2Botj0epelN4",
        "outputId": "f36180f7-126c-43ab-b818-9aced4dc8333",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ImageClassification(\n",
              "    crop_size=[224]\n",
              "    resize_size=[232]\n",
              "    mean=[0.485, 0.456, 0.406]\n",
              "    std=[0.229, 0.224, 0.225]\n",
              "    interpolation=InterpolationMode.BILINEAR\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from torchvision.models import get_weight\n",
        "\n",
        "# write your code here\n",
        "weights = get_weight('MobileNet_V2_Weights.DEFAULT')\n",
        "transforms_fn = weights.transforms()\n",
        "transforms_fn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c15dda4e",
      "metadata": {
        "id": "c15dda4e"
      },
      "source": [
        "This is its `forward()` method (of MobileNet V2 transform, that is). Take a good look at the sequence of transformations it performs because, as you probably already guesses, this function is not compatible with V2 transforms, so you'll have to include them yourself - if needed - in your data augmentation pipeline (the next section).\n",
        "\n",
        "```python\n",
        "def forward(self, img: Tensor) -> Tensor:\n",
        "    img = F.resize(img, self.resize_size, interpolation=self.interpolation, antialias=self.antialias)\n",
        "    img = F.center_crop(img, self.crop_size)\n",
        "    if not isinstance(img, Tensor):\n",
        "        img = F.pil_to_tensor(img)\n",
        "    img = F.convert_image_dtype(img, torch.float)\n",
        "    img = F.normalize(img, mean=self.mean, std=self.std)\n",
        "    return img\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "425ab7a6",
      "metadata": {
        "id": "425ab7a6"
      },
      "source": [
        "### 12.8.5 Data Augmentation\n",
        "\n",
        "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch0/data_step3.png)\n",
        "\n",
        "It is time to write your own `get_transform()` function that takes one argument, namely, ìf it is performing transformations on the training or the validation set:\n",
        "- if it is the validation set, it should stick to the basics (hint: check the prescribed transformations to assess these points)\n",
        "  - make sure the image is in the right size/shape for the backbone of your choice\n",
        "  - convert, if needed, PIL images to tensors\n",
        "  - normalize the values\n",
        "- if it is in the training set, it may perform data augmentation as well:\n",
        "  - choose one or more data augmenting transformations\n",
        "  - sanitize bounding boxes, just in case\n",
        "\n",
        "Pay special attention to the order in which transformations will happen, to make sure the transformed image at the end of the pipeline does indeed match the requirements of the backbone model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b27ec8ca",
      "metadata": {
        "id": "b27ec8ca"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from collections import defaultdict\n",
        "from torchvision.transforms import v2 as transforms\n",
        "\n",
        "augmenting = [\n",
        "    # Choose one (or more) augmentation transform(s), such as RandomHorizontalFlip, for example\n",
        "    # write your code here\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "]\n",
        "\n",
        "basic = [\n",
        "    # Include required transformations here, such as transforming PIL images into tensors\n",
        "    # and normalizing pixel values\n",
        "    # write your code here\n",
        "    transforms.ToImage(),\n",
        "    transforms.ToDtype(torch.float32, scale=True),\n",
        "    transforms.SanitizeBoundingBoxes(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "]\n",
        "\n",
        "def get_transform(train):\n",
        "    ops = [\n",
        "        # Include resizing transformations here, to make images the right size for the chosen model\n",
        "        # write your code here\n",
        "        transforms.Resize(232, antialias=True),\n",
        "        transforms.CenterCrop(224)\n",
        "    ]\n",
        "    # Only does augmenting in training mode\n",
        "    if train:\n",
        "        ops.extend(augmenting)\n",
        "    # Basic transforms: to tensor, sanitizing, and normalizing\n",
        "    ops.extend(basic)\n",
        "    return transforms.Compose(ops)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5bfd44b",
      "metadata": {
        "id": "b5bfd44b"
      },
      "source": [
        "### 12.8.6 Datasets and DataLoaders\n",
        "\n",
        "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch0/data_step4.png)\n",
        "\n",
        "In Chapter 10, we built a dataset class that handles the nitty-gritty details of wrapping images, boxes, and masks, and applying transformations to both images and targets. Let's use the same class once again. Just run the code below as is:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "a5e65871",
      "metadata": {
        "id": "a5e65871"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchvision.tv_tensors import Image, BoundingBoxes, BoundingBoxFormat, Mask\n",
        "from torchvision.ops import masks_to_boxes, box_area\n",
        "from torchvision.datasets import VisionDataset\n",
        "\n",
        "class ObjDetectionDataset(VisionDataset):\n",
        "    def __init__(self, image_folder, annotations=None, mask_folder=None, transforms=None):\n",
        "        super().__init__(image_folder, transforms, None, None)\n",
        "        # folder where images are stored\n",
        "        self.image_folder = image_folder\n",
        "        # path to a CSV file or pandas dataframe with annotations\n",
        "        self.annotations = annotations\n",
        "        # folder where masks, if any, are stored\n",
        "        self.mask_folder = mask_folder\n",
        "        # transforms/augmentations to be applied to images\n",
        "        self.transforms = transforms\n",
        "\n",
        "        # gets the list of all images sorted by name\n",
        "        self.images = list(sorted(os.listdir(image_folder)))\n",
        "\n",
        "        self.df_boxes = None\n",
        "        assert (annotations is not None) or (mask_folder is not None), \"At least one, annotations or masks, must be supplied\"\n",
        "\n",
        "        # if a CSV or dataframe was prodivded\n",
        "        if annotations is not None:\n",
        "            if isinstance(annotations, str):\n",
        "                self.df_boxes = pd.read_csv(annotations)\n",
        "            else:\n",
        "                self.df_boxes = annotations\n",
        "            # makes sure the annotations are in the XYXY format\n",
        "            assert len(set(self.df_boxes.columns).intersection({'filename', 'xmin', 'ymin', 'xmax', 'ymax'})) == 5, \"Missing columns in CSV\"\n",
        "            # only annotated images are considered - it overwrites the images attribute\n",
        "            self.images = self.df_boxes['filename'].unique().tolist()\n",
        "\n",
        "        self.masks = None\n",
        "        # if there are masks, makes sure each image has its own mask\n",
        "        if mask_folder is not None:\n",
        "            self.masks = list(sorted(os.listdir(mask_folder)))\n",
        "            assert len(self.masks) == len(self.images), \"Every image must have one, and only one, mask\"\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_filename = os.path.join(self.image_folder, self.images[idx])\n",
        "        image_tensor = read_image(image_filename, mode=ImageReadMode.RGB)\n",
        "        # gets the last two dimensions, height and width\n",
        "        image_hw = image_tensor.shape[-2:]\n",
        "\n",
        "        labels = None\n",
        "        # If there are masks, we work with them\n",
        "        if self.masks is not None:\n",
        "            mask_filename = os.path.join(self.mask_folder, self.masks[idx])\n",
        "            merged_mask = read_image(mask_filename)\n",
        "            # checks how many instances are present in the mask\n",
        "            # assumes the first one, zero, is background only\n",
        "            instances = merged_mask.unique()[1:]\n",
        "\n",
        "            # splits the merged mask, so there's one mask for instance\n",
        "            masks = (merged_mask == instances.view(-1, 1, 1))\n",
        "            # converts masks into boxes\n",
        "            boxes = masks_to_boxes(masks)\n",
        "            # uses the datapoints namespace to wrap the masks\n",
        "            wrapped_masks = Mask(masks)\n",
        "        # No masks, so we fallback to a DF of annotated boxes\n",
        "        else:\n",
        "            # retrieves the annotations for the corresponding image\n",
        "            annots = self.df_boxes.query(f'filename == \"{self.images[idx]}\"')\n",
        "            # keeps only the coordinates\n",
        "            boxes = torch.as_tensor(annots.dropna()[['xmin', 'ymin', 'xmax', 'ymax']].values)\n",
        "            # if there are labels available as well, retrieves them\n",
        "            if 'label' in annots.columns:\n",
        "                labels = torch.as_tensor(annots.dropna()['label'].values)\n",
        "            wrapped_masks = None\n",
        "\n",
        "        # uses the datapoints namespace to wrap the boxes\n",
        "        wrapped_boxes = BoundingBoxes(boxes, format=BoundingBoxFormat.XYXY, canvas_size=image_hw)\n",
        "        num_objs = len(boxes)\n",
        "\n",
        "        if len(boxes):\n",
        "            if labels is None:\n",
        "                # if there are no labels, we assume every instance is of\n",
        "                # the same, and only, class\n",
        "                labels = torch.ones((num_objs,), dtype=torch.int64)\n",
        "            area = box_area(wrapped_boxes)\n",
        "        else:\n",
        "            # Only background, no boxes\n",
        "            labels = torch.zeros((0,), dtype=torch.int64)\n",
        "            area = torch.tensor([0.], dtype=torch.float32)\n",
        "\n",
        "        # creates a target dictionary with all elements\n",
        "        target = {\n",
        "            'boxes': wrapped_boxes,\n",
        "            'area': area,\n",
        "            'labels': labels,\n",
        "            'image_id': torch.tensor([idx+1]),\n",
        "            'iscrowd': torch.zeros((num_objs,), dtype=torch.int64)\n",
        "        }\n",
        "        # if there are masks, includes them\n",
        "        if wrapped_masks is not None:\n",
        "            target['masks'] = wrapped_masks\n",
        "\n",
        "        # uses the datapoints namespace to wrap the image\n",
        "        image = Image(image_tensor)\n",
        "\n",
        "        # if there are transformations/augmentations\n",
        "        # apply them to the image and target\n",
        "        if self.transforms is not None:\n",
        "            image, target = self.transforms(image, target)\n",
        "\n",
        "        return image, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e07ca71",
      "metadata": {
        "id": "7e07ca71"
      },
      "source": [
        "Create two datasets, one for training, and one for validation, and assign the corresponding transformations to each one of them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "84c7d7d2",
      "metadata": {
        "id": "84c7d7d2",
        "outputId": "991543e3-91f8-4f23-f7a6-a113a1b86f24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 680)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "datasets = {}\n",
        "\n",
        "# write your code here\n",
        "datasets['train'] = ObjDetectionDataset(image_folder='./pets/oxford-iiit-pet/images',\n",
        "                                        annotations=annotations['train'],\n",
        "                                        transforms=get_transform(True))\n",
        "datasets['val'] = ObjDetectionDataset(image_folder='./pets/oxford-iiit-pet/images',\n",
        "                                      annotations=annotations['val'],\n",
        "                                      transforms=get_transform(False))\n",
        "\n",
        "len(datasets['train']), len(datasets['val'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ecac31d",
      "metadata": {
        "id": "5ecac31d"
      },
      "source": [
        "Next, create two data loaders, one for each dataset. You should shuffle the training set, but not the validation one. Also, keep batch size small (e.g. two) to avoid out-of-memory issues in the GPU.\n",
        "\n",
        "![](https://raw.githubusercontent.com/dvgodoy/assets/main/PyTorchInPractice/images/ch0/data_step5.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c9f19e95",
      "metadata": {
        "id": "c9f19e95"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataloaders = {}\n",
        "\n",
        "# write your code here\n",
        "dataloaders['train'] = DataLoader(datasets['train'], batch_size=2, shuffle=True)\n",
        "dataloaders['val'] = DataLoader(datasets['val'], batch_size=2, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f2ce997",
      "metadata": {
        "id": "5f2ce997"
      },
      "source": [
        "Try fetching a mini-batch from your training set. Just run the code below as is:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "78fd55e3",
      "metadata": {
        "id": "78fd55e3",
        "outputId": "edea2fa2-9961-43f7-d6a4-6b7b20953183",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[[[ 1.8037,  1.7865,  1.7694,  ...,  1.1700,  1.1529,  1.1700],\n",
              "           [ 1.8208,  1.8208,  1.8037,  ...,  1.1529,  1.1529,  1.1700],\n",
              "           [ 1.8208,  1.8379,  1.8208,  ...,  1.1529,  1.1529,  1.1700],\n",
              "           ...,\n",
              "           [ 1.5468,  1.5468,  1.6153,  ...,  0.7591,  0.8104,  0.8104],\n",
              "           [ 1.6667,  1.5468,  1.5639,  ...,  1.0844,  1.1700,  1.0502],\n",
              "           [ 1.6838,  1.6495,  1.5125,  ...,  1.0844,  1.1700,  1.1187]],\n",
              " \n",
              "          [[ 2.2710,  2.2535,  2.2360,  ...,  1.3606,  1.3431,  1.3606],\n",
              "           [ 2.2535,  2.2535,  2.2360,  ...,  1.3431,  1.3431,  1.3606],\n",
              "           [ 2.2185,  2.2360,  2.2185,  ...,  1.3431,  1.3431,  1.3606],\n",
              "           ...,\n",
              "           [ 1.7983,  1.7808,  1.8683,  ...,  0.9405,  1.0280,  1.0805],\n",
              "           [ 1.9384,  1.7983,  1.8158,  ...,  1.2731,  1.3957,  1.3431],\n",
              "           [ 1.9734,  1.9209,  1.7633,  ...,  1.3081,  1.4132,  1.4132]],\n",
              " \n",
              "          [[ 2.6051,  2.5877,  2.5703,  ...,  1.5245,  1.5071,  1.5245],\n",
              "           [ 2.5877,  2.5877,  2.5703,  ...,  1.5071,  1.5071,  1.5245],\n",
              "           [ 2.5703,  2.5877,  2.5703,  ...,  1.5071,  1.5071,  1.5245],\n",
              "           ...,\n",
              "           [ 1.6465,  1.6291,  1.6988,  ...,  0.8797,  0.9494,  1.0017],\n",
              "           [ 1.8034,  1.6465,  1.6640,  ...,  1.2108,  1.3328,  1.2631],\n",
              "           [ 1.8731,  1.8034,  1.6291,  ...,  1.1585,  1.2457,  1.2282]]],\n",
              " \n",
              " \n",
              "         [[[-1.3473, -1.4500, -1.4158,  ...,  0.6734,  0.6734,  0.6563],\n",
              "           [-1.1418, -1.3987, -1.5357,  ...,  1.7523,  1.6495,  1.5982],\n",
              "           [-1.1247, -1.2959, -1.4329,  ...,  2.0777,  2.0777,  1.9920],\n",
              "           ...,\n",
              "           [-1.5014, -1.3815, -1.3644,  ..., -1.4158, -0.8164, -0.6109],\n",
              "           [-1.5185, -1.3815, -1.3644,  ..., -1.6213, -1.1760, -0.7479],\n",
              "           [-1.5528, -1.3815, -1.3644,  ..., -1.7240, -1.5357, -1.0219]],\n",
              " \n",
              "          [[-1.3004, -1.4580, -1.4405,  ...,  0.6779,  0.7479,  0.7479],\n",
              "           [-1.1779, -1.4755, -1.6155,  ...,  1.7983,  1.7808,  1.7458],\n",
              "           [-1.2304, -1.4230, -1.5455,  ...,  2.1660,  2.2360,  2.1485],\n",
              "           ...,\n",
              "           [-1.7381, -1.7381, -1.7731,  ..., -1.5455, -0.9328, -0.7402],\n",
              "           [-1.7556, -1.7381, -1.7731,  ..., -1.7556, -1.3179, -0.8803],\n",
              "           [-1.7731, -1.7381, -1.7556,  ..., -1.8957, -1.6856, -1.1604]],\n",
              " \n",
              "          [[-1.2293, -1.3861, -1.3513,  ...,  0.7576,  0.8274,  0.8274],\n",
              "           [-1.0898, -1.3513, -1.5081,  ...,  1.9428,  1.8905,  1.8557],\n",
              "           [-1.1421, -1.3164, -1.4559,  ...,  2.3611,  2.3960,  2.2914],\n",
              "           ...,\n",
              "           [-1.6824, -1.6999, -1.7870,  ..., -1.4907, -0.9504, -0.7761],\n",
              "           [-1.6999, -1.7173, -1.7870,  ..., -1.6650, -1.2816, -0.8981],\n",
              "           [-1.7173, -1.7173, -1.7696,  ..., -1.7870, -1.6476, -1.1596]]]]),\n",
              " {'boxes': tensor([[[ 27.0877,  37.9956, 152.9387, 139.3996]],\n",
              "  \n",
              "          [[116.6200,  47.5556, 180.4800, 111.4844]]], dtype=torch.float64),\n",
              "  'area': tensor([[48708.],\n",
              "          [ 3844.]], dtype=torch.float64),\n",
              "  'labels': tensor([[8],\n",
              "          [6]]),\n",
              "  'image_id': tensor([[ 299],\n",
              "          [1735]]),\n",
              "  'iscrowd': tensor([[0],\n",
              "          [0]])}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "next(iter(dataloaders['train']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed526b2b",
      "metadata": {
        "id": "ed526b2b"
      },
      "source": [
        "Did you get an error? No? Consider yourself lucky! At some point, it will raise an error, whenever an image with either zero or more than one annotation is included in the mini-batch.\n",
        "\n",
        "The collate function is the function used by the data loader to patch together multiple data points into a mini-batch. If your dataset is nothing but tensors, that's trivial: it only has to stack them up. Stacking them up, though, assumes every data point has exactly the same shape for its features.\n",
        "\n",
        "In object detection models, though, this is not guaranteed to be the case: one image may have no boxes, another one may have three boxes, and yet another one may have only one. Those cannot be stacked together.\n",
        "\n",
        "The solution, fortunately, is pretty easy, and it looks like this:\n",
        "\n",
        "```python\n",
        "lambda batch: tuple(zip(*batch))\n",
        "```\n",
        "\n",
        "Throw the lambda function above as the `collate_fn` argument of your data loaders, and try again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "8aaa06ba",
      "metadata": {
        "id": "8aaa06ba",
        "outputId": "4eb6ee78-3d58-4bb1-d176-9743290c5ef5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((Image([[[-0.5938, -0.0801,  0.3994,  ..., -0.9534, -1.3473, -1.2788],\n",
              "          [-0.6794, -0.0458,  0.5536,  ..., -0.7650, -1.2617, -1.4843],\n",
              "          [-0.3027,  0.0741,  0.5193,  ..., -0.7137, -1.1075, -1.6042],\n",
              "          ...,\n",
              "          [ 0.1768,  0.7762,  0.0741,  ...,  0.0741, -0.0972, -0.6794],\n",
              "          [-0.3541, -0.4226,  0.2453,  ..., -0.3541, -0.4226, -0.8335],\n",
              "          [-1.0390, -1.3473, -0.7650,  ..., -1.0562, -1.2445, -1.3644]],\n",
              "  \n",
              "         [[-0.0749,  0.5553,  1.1681,  ..., -0.4251, -0.6176, -0.5826],\n",
              "          [-0.1099,  0.6254,  1.3256,  ..., -0.0924, -0.6702, -0.8803],\n",
              "          [ 0.1877,  0.8179,  1.3606,  ..., -0.0224, -0.5476, -1.0553],\n",
              "          ...,\n",
              "          [ 0.0301,  0.8179,  0.4853,  ...,  0.6604,  0.5378,  0.0651],\n",
              "          [-0.3901, -0.3375,  0.3627,  ...,  0.3102,  0.1702, -0.1275],\n",
              "          [-0.6702, -0.9328, -0.5826,  ..., -0.4601, -0.8277, -1.0028]],\n",
              "  \n",
              "         [[-0.3404,  0.1128,  0.4788,  ..., -1.2816, -1.3513, -1.3687],\n",
              "          [-0.4973, -0.2184,  0.3916,  ..., -1.4559, -1.2641, -1.1944],\n",
              "          [-0.0964, -0.2010,  0.5485,  ..., -1.2293, -1.1596, -1.1944],\n",
              "          ...,\n",
              "          [ 0.0605,  0.6182, -0.3055,  ...,  0.5659,  0.4614, -0.2010],\n",
              "          [-0.6890, -0.9156, -0.1661,  ...,  0.0779,  0.0953, -0.2184],\n",
              "          [-1.0201, -1.2816, -0.7761,  ..., -0.6193, -0.9156, -1.1247]]], ),\n",
              "  Image([[[-0.9020, -0.8849, -0.8849,  ..., -1.0048, -1.0219, -1.0219],\n",
              "          [-0.9192, -0.9363, -0.9705,  ..., -1.0048, -1.0048, -1.0219],\n",
              "          [-0.9705, -0.9877, -0.9705,  ..., -1.0219, -1.0390, -1.0562],\n",
              "          ...,\n",
              "          [-1.3987, -1.3815, -1.3644,  ..., -0.1314, -0.1999, -0.1143],\n",
              "          [-1.4329, -1.3815, -1.3473,  ..., -0.0629, -0.1143, -0.2171],\n",
              "          [-1.3987, -1.3473, -1.3130,  ..., -0.0287, -0.1143, -0.2513]],\n",
              "  \n",
              "         [[-0.7577, -0.7402, -0.7402,  ..., -0.8452, -0.8627, -0.8627],\n",
              "          [-0.7752, -0.7927, -0.8277,  ..., -0.8452, -0.8452, -0.8627],\n",
              "          [-0.8277, -0.8452, -0.8277,  ..., -0.8627, -0.8803, -0.8978],\n",
              "          ...,\n",
              "          [-1.2304, -1.2129, -1.1954,  ..., -0.7577, -0.8102, -0.7227],\n",
              "          [-1.2654, -1.2129, -1.1779,  ..., -0.6702, -0.7227, -0.8452],\n",
              "          [-1.2304, -1.1779, -1.1429,  ..., -0.6352, -0.7227, -0.8627]],\n",
              "  \n",
              "         [[-0.1487, -0.1487, -0.1487,  ..., -0.3230, -0.3404, -0.3404],\n",
              "          [-0.1661, -0.1835, -0.2184,  ..., -0.3404, -0.3404, -0.3404],\n",
              "          [-0.2010, -0.2184, -0.2010,  ..., -0.3753, -0.3927, -0.3927],\n",
              "          ...,\n",
              "          [-0.8110, -0.7936, -0.7761,  ..., -1.2293, -1.2816, -1.1944],\n",
              "          [-0.8458, -0.7936, -0.7587,  ..., -1.1421, -1.1770, -1.2990],\n",
              "          [-0.8110, -0.7587, -0.7238,  ..., -1.1073, -1.2119, -1.3339]]], )),\n",
              " ({'boxes': BoundingBoxes([[ 17.6533,   0.0000, 169.2267, 160.0860]], dtype=torch.float64, format=BoundingBoxFormat.XYXY, canvas_size=(224, 224)),\n",
              "   'area': tensor([79870.], dtype=torch.float64),\n",
              "   'labels': tensor([32]),\n",
              "   'image_id': tensor([2764]),\n",
              "   'iscrowd': tensor([0])},\n",
              "  {'boxes': BoundingBoxes([[  5.0080,  16.2651, 189.2800, 172.7952]], dtype=torch.float64, format=BoundingBoxFormat.XYXY, canvas_size=(224, 224)),\n",
              "   'area': tensor([59136.], dtype=torch.float64),\n",
              "   'labels': tensor([2]),\n",
              "   'image_id': tensor([42]),\n",
              "   'iscrowd': tensor([0])}))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "dataloaders = {}\n",
        "\n",
        "# write your code here\n",
        "dataloaders['train'] = DataLoader(datasets['train'], batch_size=2, shuffle=True, collate_fn=lambda batch: tuple(zip(*batch)))\n",
        "dataloaders['val'] = DataLoader(datasets['val'], batch_size=2, shuffle=False, collate_fn=lambda batch: tuple(zip(*batch)))\n",
        "\n",
        "next(iter(dataloaders['train']))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}